fedml_params:
  fedml_account_id: 1111
  project_name: Cheetah_HelloWorld
  job_name: Cheetah_HelloWorld3

development_resources:
  dev_env: "https://open.fedml.ai"  # development resources bundle to load on each machine
  network: mqtt_s3    # network protocol for communication between machines

executable_code_and_data:
  # The entire command will be executed as follows:
  # executable_interpreter executable_file executable_conf_option executable_conf_file executable_args
  # e.g. python hello_world/torch_client.py --cf hello_world/config/fedml_config.yaml --rank 1
  # e.g. deepspeed <client_entry.py> --deepspeed_config ds_config.json --num_nodes=2 --deepspeed <client args>
  # e.g. python --version (executable_interpreter=python, executable_args=--version, any else is empty)
  # e.g. echo "Hello World!" (executable_interpreter=echo, executable_args="Hello World!", any else is empty)
  executable_interpreter: python                   # shell interpreter for executable_file, e.g. bash, sh, zsh, python, etc.
  executable_file: hello_world/job_entry.py     # your main executable file in the base directory, which can be empty
  executable_conf_option: --cf  # your command option for executable_conf_file, which can be empty
  executable_conf_file: hello_world/config/fedml_config.yaml   # your config file for the main executable program in the base directory, which can be empty
  executable_args: --rank 1            # command arguments for the executable_interpreter and executable_file
  data_location: ~/fedml_data          # path to your data
  # bootstrap shell commands which will be executed before running executable_file. support multiple lines, which can be empty
  bootstrap: | 
    ls -la ~               
    echo "Bootstrap..."
gpu_requirements:
  minimum_num_gpus: 1             # minimum # of GPUs to provision
  maximum_cost_per_hour: $1.75    # max cost per hour for your job per machine